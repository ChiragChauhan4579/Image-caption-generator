{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data-preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfxRCr1YwCnj"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip"
      ],
      "metadata": {
        "id": "iYLHT9VTwePp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/Flickr8k_Dataset.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6SToWOe1DNk",
        "outputId": "d05fbfa3-9c67-40ec-b6ac-d5e6c8e23a54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/Flickr8k_text.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgrT43Zm1J1s",
        "outputId": "cb23baf2-1d3e-426f-8433-7ca31bf2a84a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir,path\n",
        "from pickle import dump\n",
        "import re\n",
        "import string\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "wYkNJTqoyk5m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(directory):\n",
        "    model = VGG16()\n",
        "    model.layers.pop()\n",
        "    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "    model.summary()\n",
        "    features = dict()\n",
        "    for name in listdir(directory):\n",
        "        filename = directory + '/' + name\n",
        "        image = load_img(filename, target_size=(224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "        image = preprocess_input(image)\n",
        "        feature = model.predict(image, verbose=0)\n",
        "        image_id = name.split('.')[0]\n",
        "        features[image_id] = feature\n",
        "    return features"
      ],
      "metadata": {
        "id": "XbsdZyEzwheL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/Flicker8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "dump(features, open('features.pkl', 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMIccSJMyvJc",
        "outputId": "8c7f43f1-84bf-4fcc-bf72-c5409a8f2029"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 5s 0us/step\n",
            "553476096/553467096 [==============================] - 5s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Extracted Features: 8091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_doc(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "filename = '/content/Flickr8k.token.txt'\n",
        "doc = load_doc(filename)"
      ],
      "metadata": {
        "id": "133t1imsy3Im"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_descriptions(doc):\n",
        "    mapping = dict()\n",
        "    for line in doc.split('\\n'):\n",
        "        tokens = line.split()\n",
        "        if len(line) < 2:\n",
        "            continue\n",
        "        image_id, image_desc = tokens[0], tokens[1:]\n",
        "        image_id = image_id.split('.')[0]\n",
        "        image_desc = ' '.join(image_desc)\n",
        "        if image_id not in mapping:\n",
        "            mapping[image_id] = list()\n",
        "            mapping[image_id].append(image_desc)\n",
        "    return mapping\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))"
      ],
      "metadata": {
        "id": "enXrhGAEzF8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04361e0-5489-4b9c-a6d5-b01893db6011"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: 8092 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_descriptions(descriptions):\n",
        "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "    for key, desc_list in descriptions.items():\n",
        "        for i in range(len(desc_list)):\n",
        "            desc = desc_list[i]\n",
        "            desc = desc.split()\n",
        "            desc = [word.lower() for word in desc]\n",
        "            desc = [re_punc.sub('', w) for w in desc]\n",
        "            desc = [word for word in desc if len(word)>1]\n",
        "            desc = [word for word in desc if word.isalpha()]\n",
        "            desc_list[i] = ' '.join(desc)\n",
        "clean_descriptions(descriptions)"
      ],
      "metadata": {
        "id": "1C3dp7VYzcmV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_vocabulary(descriptions):\n",
        "    all_desc = set()\n",
        "    for key in descriptions.keys():\n",
        "        [all_desc.update(d.split()) for d in descriptions[key]]\n",
        "    return all_desc\n",
        "\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))"
      ],
      "metadata": {
        "id": "kscRDUiQznpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feff473a-9ae9-4a58-f00e-64ef7e113d90"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 4473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_descriptions(descriptions, filename):\n",
        "    lines = list()\n",
        "    for key, desc_list in descriptions.items():\n",
        "        for desc in desc_list:\n",
        "            lines.append(key + ' ' + desc)\n",
        "            data = '\\n'.join(lines)\n",
        "            file = open(filename, 'w')\n",
        "            file.write(data)\n",
        "            file.close()\n",
        "\n",
        "save_descriptions(descriptions, 'descriptions.txt')"
      ],
      "metadata": {
        "id": "k9mw8XeAzt39"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}